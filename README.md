# ğŸ’³ Credit Card QA â€“ RAG System

A **RAG** pipeline for answering queries about Indian credit cards.

---

## Current Status

- Extract and chunk data 
- Embeddings using Hugging Faceâ€™s `all-MiniLM-L6-v2`
- **Pinecone** for semantic search
- 

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ loader.py        # PDF extraction
â”‚   â”œâ”€â”€ splitter.py      # Text chunking
â”‚   â”œâ”€â”€ embedder.py      # Hugging Face embeddings
â”‚   â”œâ”€â”€ retriever.py     # Pinecone search
â”‚   â””â”€â”€ main.py          # FastAPI app
â”œâ”€â”€ data/pdfs/           # Source documents
â”œâ”€â”€ pinecone_setup.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Stack
- **LLM:** LLama 3
- **Embedding Model:** `sentence-transformers/all-MiniLM-L6-v2`
- **Vector DB:** Pinecone
- **API:** FastAPI
- **Tools:** LangChain

---

## ğŸ”§ Quick Start

```bash
# Setup environment
python3 -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Start API server
python -m app.main 
```

---

## ğŸ›£ï¸ Roadmap

- Add Fast API backend
- Add LLM for response generation (Mistral, LLaMA 3)
- Integrate Chain-of-Thought reasoning
- Streamlit UI
- Docker + CI/CD pipeline
- Logging & observability for MLOps

---
